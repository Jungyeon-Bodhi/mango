{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b6eea0-7f63-4419-97de-0b7ba016418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pandas.plotting import table\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from scipy.stats import normaltest\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55284877-10a8-4441-a346-3ae8bf348800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicator:\n",
    "    \n",
    "    def __init__(self, df, name, number, var, i_cal, i_type, description, period, target):\n",
    "        \"\"\"\n",
    "        - Initialise the Indicator class\n",
    "\n",
    "        name: str, Name of the indicator\n",
    "        number: int, Number associated with the indicator\n",
    "        var: list, Variable of the indicator (Questions)\n",
    "        i_cal: str, How to calculate the indicator ('descriptive' or 'score')\n",
    "        i_type: str, Type of the indicator ('Count' or 'Percentage')\n",
    "        description: str, Description of the indicator\n",
    "        period: str, Period when the indicator is measured ('baseline', 'midline', or 'endline')\n",
    "        targets: int, A target for this survey\n",
    "        score_map: dic, 해당 인디케이터의 스코어를 계산하는 방법\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.name = name\n",
    "        self.number = number\n",
    "        self.var = var\n",
    "        if len(var) == 1:\n",
    "            self.var_type = 'single'\n",
    "        else: self.var_type = 'multi'\n",
    "        self.indicator_name = f'{name}{number}'\n",
    "        self.i_cal = i_cal\n",
    "        self.i_type = i_type.capitalize()\n",
    "        self.description = description\n",
    "        self.period = period\n",
    "        self.target = target\n",
    "        self.baseline = None\n",
    "        self.midline = None\n",
    "        self.var_order = None\n",
    "        self.score_map = None\n",
    "        self.valid_point = None\n",
    "        self.breakdown = None\n",
    "        self.condition = None\n",
    "\n",
    "    def info(self):\n",
    "        print(f\"Indicator: {self.name}.{self.number} | Indicator type: {self.i_type} ({self.i_cal})\\nDescription: {self.description} \\nPeriod: {self.period} | Target: {self.target}\")\n",
    "        if self.baseline != None:\n",
    "            print(f\"This indicator's baseline value was {self.baseline}\")\n",
    "        if self.midline != None:\n",
    "            print(f\"This indicator's midline value was {self.midline}\")\n",
    "\n",
    "    def get_target(self):\n",
    "        \"\"\"\n",
    "        Get the target value\n",
    "        \"\"\"\n",
    "        print(f\"The target value for {self.period} is {self.target}\")\n",
    "        return self.target\n",
    "    \n",
    "    def update_target(self, value):\n",
    "        self.target = value\n",
    "        print(\"Target value has been updated\")\n",
    "        return True\n",
    "\n",
    "    def add_baseline(self, value):\n",
    "        self.baseline = value\n",
    "\n",
    "    def add_midline(self, value):\n",
    "        self.midline = value\n",
    "\n",
    "    def add_var_order(self, order):\n",
    "        self.var_order = order\n",
    "\n",
    "    def add_score_map(self, score_map):\n",
    "        self.score_map = score_map\n",
    "\n",
    "    def add_valid_point(self, point):\n",
    "        self.valid_point = point\n",
    "\n",
    "    def add_breakdown(self, breakdown):\n",
    "        \"\"\"\n",
    "        - Add the condiction of breakdown of this data\n",
    "\n",
    "        breakdown: dic, Combination of breakdown columns and its name: {'col1':'gender'}\n",
    "        \"\"\"\n",
    "        self.breakdown = breakdown\n",
    "        print(f\"{self.indicator_name} will be broken down by {', '.join(self.breakdown.values())}\")\n",
    "\n",
    "    def add_condition(self, conditions):\n",
    "        # (df['2'] > 25) & (df['4'] = 'Male')\n",
    "        self.condition = conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540dc63f-df94-47af-a242-4fc1c060a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/24-PI-NG-1 CAY_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa9823d-e16e-4014-b30e-25930fe6751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leao111 = Indicator(df, \"LEAO\", 111, ['21-1', '21-2', '21-3', '21-4', '21-5'], i_cal='score_average', i_type='percentage', description='Number of something', period='endline', target =96.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806d77cd-8449-4b61-80d6-55febc7708f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAO111 will be broken down by Gender, Region\n"
     ]
    }
   ],
   "source": [
    "leao111.add_baseline(30.2)\n",
    "leao111.add_midline(43.9)\n",
    "leao111.add_score_map({\n",
    "        'Strongly agree': 3,\n",
    "        'Agree': 2,\n",
    "        'Disagree': 1,\n",
    "        'Strongly disagree': 0\n",
    "        })\n",
    "leao111.add_valid_point(2)\n",
    "leao111.add_condition((df['2'] > 25) & (df['4'] == 'Male'))\n",
    "leao111.add_breakdown({'4':'Gender', 's1':'Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f993f170-65aa-4685-be7a-e31307091a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROO311 will be broken down by Gender, Region\n"
     ]
    }
   ],
   "source": [
    "srhi311 = Indicator(df, \"PROO\", 311, ['14'], i_cal='devide', i_type='percentage', description='Number of something', period='endline', target = 96.1)\n",
    "# No score map\n",
    "df['14'] = pd.to_numeric(df['14'], errors='coerce')\n",
    "srhi311.add_baseline(30.2)\n",
    "srhi311.add_midline(43.9)\n",
    "srhi311.add_valid_point({15: 'Before 15', (15, 18): 'Before 18', 18: 'After 18'})\n",
    "srhi311.add_condition((df['4'] == 'Female') & (df['2'] >= 15) &(df['2'] <= 24))\n",
    "srhi311.add_breakdown({'4':'Gender', 's1':'Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f2bf60-90ef-4c4b-bf61-568da3bf067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROO141 will be broken down by Gender, Region\n"
     ]
    }
   ],
   "source": [
    "proo141 = Indicator(df, \"PROO\", 141, ['89', '91', '93', '95'], i_cal='score_select_allyes', i_type='percentage', description='Number of something', period='endline', target = 96.1)\n",
    "# No score map\n",
    "proo141.add_baseline(30.2)\n",
    "proo141.add_midline(43.9)\n",
    "proo141.add_valid_point(2)\n",
    "proo141.add_breakdown({'4':'Gender', 's1':'Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5747d792-e252-432d-ad98-749d3909d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator: LEAO.111 | Indicator type: percentage (score_average)\n",
      "Description: Number of something \n",
      "Period: endline | Target: 96.1\n",
      "This indicator's baseline value was 30.2\n",
      "This indicator's midline value was 43.9\n"
     ]
    }
   ],
   "source": [
    "leao111.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6260121-237e-4c36-9528-fc021ba7684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "\n",
    "bodhi_blue = (0.0745, 0.220, 0.396)\n",
    "bodhi_grey = (0.247, 0.29, 0.322)\n",
    "bodhi_primary_1 = (0.239, 0.38, 0.553)\n",
    "bodhi_secondary = (0.133, 0.098, 0.42)\n",
    "bodhi_tertiary = (0.047, 0.396, 0.298)\n",
    "bodhi_complement = (0.604, 0.396, 0.071)\n",
    "\n",
    "class Data_analysis:\n",
    "\n",
    "    def __init__(self, name, indicators):\n",
    "        self.name = name\n",
    "        self.indicators = indicators\n",
    "\n",
    "    def count(self, df, var, index_name):\n",
    "        count = df[var].value_counts()\n",
    "        count_df = pd.DataFrame({'Count': count})\n",
    "        count_df['Percentage'] = round(count_df['Count'] / count_df['Count'].sum() * 100, 1)\n",
    "        count_df.index.name = index_name\n",
    "        return count_df\n",
    "\n",
    "    def multi_table(self, df, columns, categories, change, column_labels, index_name):\n",
    "        table = pd.DataFrame(index=categories)\n",
    "        for col in columns:\n",
    "            table[col] = df[col].value_counts().reindex(categories, fill_value=0)\n",
    "        if column_labels is not None:\n",
    "            table.columns = column_labels\n",
    "        if change is not None:\n",
    "            table.index = change[:len(table)]\n",
    "        return table\n",
    "\n",
    "    def tables(self, file_path):\n",
    "        for indicator in self.indicators:\n",
    "            sheet_name = indicator.indicator_name\n",
    "            var_name = indicator.description\n",
    "            df = indicator.df\n",
    "            var = indicator.var\n",
    "            dis_cols = list(indicator.breakdown.keys())\n",
    "            dfs = {}\n",
    "            book = load_workbook(file_path)\n",
    "            \n",
    "            if indicator.var_order is not None:\n",
    "                df[var] = df[var].astype('category')\n",
    "                df[var] = df[var].cat.set_categories(indicator.var_order, ordered=True)\n",
    "                \n",
    "            if dis_cols != None:\n",
    "                melted = df.melt(id_vars=dis_cols, value_vars=var, var_name=' ', value_name='category_value')\n",
    "                for col, i in zip(dis_cols, range(len(dis_cols))):\n",
    "                    count_df = melted.groupby(['category_value', col]).size().unstack(fill_value=0)\n",
    "                    percent_df = round(count_df.div(count_df.sum(axis=0), axis=1) * 100, 2)\n",
    "                    f_df = pd.concat([count_df, percent_df.add_suffix('(%)')], axis=1)\n",
    "                    dfs[f'final_df{i}'] = f_df.transpose()\n",
    "                    \n",
    "            final_df = pd.concat(dfs, axis=0)\n",
    "            overall_df = self.count(df, var, index_name=indicator.indicator_name)\n",
    "            \n",
    "            with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "                final_df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "                startrow = final_df.shape[0] + 2\n",
    "                overall_df.to_excel(writer, sheet_name=sheet_name, startrow=startrow, index=True, header=True)\n",
    "                \n",
    "            wb = load_workbook(file_path)\n",
    "            ws = wb[sheet_name]\n",
    "            ws.insert_rows(1)\n",
    "            ws['B1'] = var_name\n",
    "            ws['B1'].font = Font(bold=True)\n",
    "            for column in ws.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if cell.value:\n",
    "                            max_length = max(max_length, len(str(cell.value)))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = (max_length + 2)\n",
    "                ws.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "            wb.save(file_path)\n",
    "\n",
    "    def chi2_test(self, file_path):\n",
    "        def chi2(df2, dependent_var, col, alpha=0.05):\n",
    "            contingency_table = pd.crosstab(df2[dependent_var], df2[col])\n",
    "            chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "        \n",
    "            print(f\"Chi-square test statistic: {chi2}\")\n",
    "            print(f\"P-value: {p_value}\")\n",
    "            var = f'Chi-square Test - {col}'\n",
    "        \n",
    "            if p_value < alpha:\n",
    "                print(f\"Variable: {col} | There is a significant association between {dependent_var} and {col}\")\n",
    "                print(\"\")\n",
    "            else:\n",
    "                print(f\"Variable: {col} | There is not a significant association between {dependent_var} and {col}\")\n",
    "                print(\"\")\n",
    "            \n",
    "            result_df = pd.DataFrame({'Test': [var],'Statistics': [chi2],'P-value': [p_value]})\n",
    "            return result_df\n",
    "        \n",
    "        for indicator in self.indicators:\n",
    "\n",
    "            sheet_name = indicator.indicator_name\n",
    "            var_name = indicator.description\n",
    "            df = indicator.df\n",
    "            dfs = {}\n",
    "            dis_cols = list(indicator.breakdown.keys())\n",
    "            book = load_workbook(file_path)\n",
    "            \n",
    "            for col, i in zip(dis_cols, range(len(dis_cols))):\n",
    "                f_df = chi2(df, indicator.var, col, alpha = 0.05)\n",
    "                dfs[f'final_df{i}'] = f_df\n",
    "            final_df = pd.concat(dfs, axis=0)\n",
    "            \n",
    "            with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                final_df.to_excel(writer, sheet_name=sheet_name, index=False, header=True)\n",
    "                \n",
    "            wb = load_workbook(file_path)\n",
    "            ws = wb[sheet_name]\n",
    "            ws.insert_rows(1)\n",
    "            ws['A1'] = var_name\n",
    "            ws['A1'].font = Font(bold=True)\n",
    "            for column in ws.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if cell.value:\n",
    "                            max_length = max(max_length, len(str(cell.value)))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = (max_length + 2)\n",
    "                ws.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "            wb.save(file_path)\n",
    "\n",
    "    def calculation(self, indicator, method):\n",
    "        \n",
    "        if method == \"score\":\n",
    "            if indicator.score_map != None:\n",
    "                df = indicator.df\n",
    "                df['score'] = df[indicator.var].map(indicator.score_map)\n",
    "                df['variable'] = df['score'].apply(lambda x: 'Pass' if x >= indicator.valid_point else 'Not Pass')\n",
    "                df.drop(columns=['score'], inplace = True)\n",
    "            else: df['variable'] = df[indicator.var].apply(lambda x: 'Pass' if x >= indicator.valid_point else 'Not Pass')\n",
    "                \n",
    "        elif method == \"devide\":\n",
    "            df = indicator.df\n",
    "            df = df.dropna(subset=indicator.var)\n",
    "            \n",
    "            def apply_valid_points(df, var, valid_points):\n",
    "                if var[0] not in df.columns:\n",
    "                    raise KeyError(f\"Column '{var}' does not exist in the dataframe.\")\n",
    "                series = df[var]\n",
    "                df = df.dropna(subset=var)\n",
    "                int_keys = [key for key in valid_points.keys() if isinstance(key, int)]\n",
    "                tuple_keys = [key for key in valid_points.keys() if isinstance(key, tuple)]\n",
    "                sorted_int_keys = sorted(int_keys)\n",
    "                sorted_tuple_keys = sorted(tuple_keys, key=lambda x: x[0])\n",
    "                conditions = []\n",
    "                choices = []\n",
    "                for key in sorted_tuple_keys:\n",
    "                    lower_bound, upper_bound = key\n",
    "                    conditions.append((df[var] > lower_bound) & (df[var] <= upper_bound))\n",
    "                    choices.append(valid_points[key])\n",
    "                for i, key in enumerate(sorted_int_keys):\n",
    "                    if i == 0:\n",
    "                        conditions.append(df[var] <= key)\n",
    "                    elif i == len(sorted_int_keys) - 1:\n",
    "                        conditions.append(df[var] > key)\n",
    "                    else:\n",
    "                        conditions.append((df[var] > sorted_int_keys[i-1]) & (df[var] <= key))\n",
    "                    choices.append(valid_points[key])\n",
    "    \n",
    "                if len(choices) < len(conditions):\n",
    "                    choices.append(' ')\n",
    "    \n",
    "                df['variable'] = np.select(conditions, choices, default=' ')\n",
    "                return df\n",
    "\n",
    "            df = apply_valid_points(df, indicator.var, indicator.valid_point)\n",
    "            \n",
    "        elif method == \"score_average\":\n",
    "            df = indicator.df\n",
    "            if indicator.score_map != None:\n",
    "                def scoring(row):\n",
    "                    score = 0\n",
    "                    columns = indicator.var\n",
    "                    for col in columns:\n",
    "                        score += indicator.score_map.get(row[col], 0)\n",
    "                    return score / len(columns)\n",
    "                df['score'] = df.apply(scoring, axis=1)\n",
    "                df['variable'] = df['score'].apply(lambda x: 'Pass' if x >= indicator.valid_point else 'Not Pass')\n",
    "                df.drop(columns=['score'], inplace = True)\n",
    "            else: print(\"Please assign the score map for calculation\")\n",
    "\n",
    "        elif method == \"score_sum\":\n",
    "            if indicator.score_map != None:\n",
    "                df = indicator.df\n",
    "                def scoring(row):\n",
    "                    score = 0\n",
    "                    columns = indicator.var\n",
    "                    for col in columns:\n",
    "                        score += indicator.score_map.get(row[col], 0)\n",
    "                    return score\n",
    "                df['score'] = df.apply(scoring, axis=1)\n",
    "                df['variable'] = df['score'].apply(lambda x: 'Pass' if x >= indicator.valid_point else 'Not Pass')\n",
    "                df.drop(columns=['score'], inplace = True)\n",
    "            else: print(\"Please assign the score map for calculation\")\n",
    "\n",
    "        # How many questions the respondents answered?\n",
    "        elif method == \"score_select\":\n",
    "            df = indicator.df\n",
    "            def scoring(row):\n",
    "                selected_count = sum([row[var] for var in indicator.var])\n",
    "                if selected_count >= indicator.valid_point:\n",
    "                    return 'Pass'\n",
    "                else: return 'Not Pass'\n",
    "            df['variable'] = \"\"\n",
    "            df['variable'] = df2.apply(scoring, axis=1)\n",
    "            \n",
    "        elif method == \"score_select_allyes\":\n",
    "            df = indicator.df\n",
    "            df['response'] = df.apply(lambda row: all(row[var] == 'Yes' for var in indicator.var), axis=1)\n",
    "            df['variable'] = df['response'].apply(lambda x: 'Pass' if x else 'Not Pass')\n",
    "            df.drop(columns=['response'], inplace = True)\n",
    "\n",
    "        elif method == \"score_select_allno\":\n",
    "            df = indicator.df\n",
    "            df['response'] = df.apply(lambda row: all(row[var] == 'No' for var in indicator.var), axis=1)\n",
    "            df['variable'] = df['response'].apply(lambda x: 'Pass' if x else 'Not Pass')\n",
    "            df.drop(columns=['response'], inplace = True)\n",
    "\n",
    "        elif method == \"score_select_\banyyes\":\n",
    "            df = indicator.df\n",
    "            df['response'] = df.apply(lambda row: any(row[var] == 'Yes' for var in indicator.var), axis=1)\n",
    "            df['variable'] = df['response'].apply(lambda x: 'Pass' if x else 'Not Pass')\n",
    "            df.drop(columns=['response'], inplace = True)\n",
    "\n",
    "        elif method == \"score_select_anyno\":\n",
    "            df = indicator.df\n",
    "            df['response'] = df.apply(lambda row: any(row[var] == 'No' for var in indicator.var), axis=1)\n",
    "            df['variable'] = df['response'].apply(lambda x: 'Pass' if x else 'Not Pass')\n",
    "            df.drop(columns=['response'], inplace = True)\n",
    "\n",
    "        # Manual Code for multiple selecting\n",
    "        elif method == \"score_select_manual\":\n",
    "            df = indicator.df\n",
    "            def scoring(row):\n",
    "                score = 0\n",
    "                for col in ['col1', 'col2', 'col3', 'col4']:\n",
    "                    if row[col] == 'Yes': # Assign and adjust the response for +1 score\n",
    "                        score += 1 # Please adjust this score\n",
    "                    elif row[col] == 'No': # Assign the response for -1 score\n",
    "                        score -= 1 # Please adjust this score\n",
    "                for col in ['col5', 'col6']: # Assign the response for +1 score\n",
    "                    if row[col] == 'No':\n",
    "                        score += 1 # Please adjust this score\n",
    "                return score\n",
    "            df['score'] = df.apply(scoring, axis=1)\n",
    "            df['variable'] = df['score'].apply(lambda x: 'Pass' if x >= indicator.valid_point else 'Not Pass')\n",
    "            df.drop(columns=['score'], inplace = True)        \n",
    "            \n",
    "        indicator.var = 'variable'\n",
    "        indicator.df = df\n",
    "            \n",
    "\n",
    "    def indicator_analysis(self):\n",
    "        for indicator in self.indicators:\n",
    "            if indicator.condition is None:\n",
    "                df_copy = indicator.df\n",
    "            else:\n",
    "                df_copy = indicator.df\n",
    "                df_copy = df_copy[indicator.condition]\n",
    "            \n",
    "            indicator.df = df_copy\n",
    "            self.calculation(indicator, indicator.i_cal)\n",
    "        return print(\"All indicators have been calculated\")\n",
    "\n",
    "    def breakdown_count_bar(self, indicator, df, colname, file_path, figsize=(12, 8), rotation=0, fontsize=12):\n",
    "        ax = df.plot(kind='bar', stacked=False, width=0.45, figsize=figsize)\n",
    "        title = f'{indicator.description}\\nby {colname}'\n",
    "        output_file = f'{file_path}_{self.indicator_name}_{colname}'\n",
    "        \n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(title)\n",
    "    \n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2, height), ha='center', va='bottom', fontsize=fontsize)\n",
    "            \n",
    "        def replace_spaces_with_newlines(label):\n",
    "            return label.replace(' ', '\\n')\n",
    "    \n",
    "        labels = [replace_spaces_with_newlines(label) for label in df.index]\n",
    "        plt.title(title, fontsize=fontsize + 4)\n",
    "        plt.xlabel(\" \", fontsize=fontsize)\n",
    "        plt.ylabel(indicator.i_type, fontsize = fontsize)\n",
    "        plt.xticks(ticks=df.index, labels=labels, rotation=rotation, fontsize=fontsize+4)\n",
    "        plt.savefig(output_file, bbox_inches='tight', dpi=800)\n",
    "\n",
    "    def breakdown_percentage_bar(self, indicator, df, colname, file_path, figsize=(12, 8), rotation=0, fontsize=12):\n",
    "        ax = df.plot(kind='bar', stacked=False, width=0.45, figsize=figsize)\n",
    "        title = f'{indicator.description}\\nby {colname}'\n",
    "        output_file = f'{file_path}_{self.indicator_name}_{colname}'\n",
    "        \n",
    "        ax.set_ylabel('Percentage')\n",
    "        ax.set_title(title)\n",
    "    \n",
    "        for i in ax.containers:\n",
    "            ax.bar_label(i, labels=[f'{p:.1f}%' for p in df[i.get_label()]], label_type='edge', fontsize=fontsize)\n",
    "            \n",
    "        def replace_spaces_with_newlines(label):\n",
    "            return label.replace(' ', '\\n')\n",
    "    \n",
    "        labels = [replace_spaces_with_newlines(label) for label in df.index]\n",
    "        plt.title(title, fontsize=fontsize + 4)\n",
    "        plt.xlabel(\" \", fontsize=fontsize)\n",
    "        plt.ylabel(indicator.i_type, fontsize = fontsize)\n",
    "        plt.ylim(0, 105)\n",
    "        plt.yticks([0, 20, 40, 60, 80, 100])\n",
    "        plt.xticks(ticks=df.index, labels=labels, rotation=rotation, fontsize=fontsize+4)\n",
    "        plt.savefig(output_file, bbox_inches='tight', dpi=800)\n",
    "\n",
    "    def plot_bar(self, indicator, df, file_path, figsize=(12, 8), rotation=0, fontsize=12):\n",
    "        title = indicator.description\n",
    "        output_file = f'{file_path}_{self.indicator_name}'\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        palette = [bodhi_complement, bodhi_blue, bodhi_tertiary, bodhi_primary_1, bodhi_grey, bodhi_secondary]\n",
    "        \n",
    "        df2 = df['Count']\n",
    "        df = df[col]\n",
    "        bars = df.plot(kind='bar', color=palette)\n",
    "\n",
    "        if indicator.i_type == 'Count':\n",
    "            for bar, value in zip(bars.patches, df2.values):   \n",
    "                percentage = (value / df2.values.sum()) * 100\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                     f'{value} ({percentage:.1f}%)',\n",
    "                     ha='center', va='bottom', fontsize=fontsize+2)\n",
    "            \n",
    "        elif indicator.i_type == 'Percent':\n",
    "            for bar, value in zip(bars.patches, df2.values):   \n",
    "                percentage = (value / df2.values.sum()) * 100\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                     f'{percentage:.1f}% ({value})',\n",
    "                     ha='center', va='bottom', fontsize=fontsize+2)\n",
    "            plt.ylim(0, 105)\n",
    "            plt.yticks([0, 20, 40, 60, 80, 100])\n",
    "            \n",
    "        def replace_spaces_with_newlines(label):\n",
    "            return label.replace(' ', '\\n')\n",
    "    \n",
    "        labels = [replace_spaces_with_newlines(label) for label in df.index]\n",
    "        plt.title(title, fontsize=fontsize + 4)\n",
    "        plt.xlabel(\" \", fontsize=fontsize)\n",
    "        plt.ylabel(indicator.i_type, fontsize = fontsize)\n",
    "        plt.xticks(ticks=df.index, labels=labels, rotation=rotation, fontsize=fontsize+4)\n",
    "        \n",
    "        plt.savefig(output_file, bbox_inches='tight', dpi=800)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cb031ee-a7c6-47ae-8f51-d1519a3301b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        - Initialise the data analysis pipeline class\n",
    "\n",
    "        name: str, Name of the project\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.indicators = []\n",
    "\n",
    "    def add_indicators(self, indicators):\n",
    "        \"\"\"\n",
    "        - Add the project indicators to the pipeline\n",
    "\n",
    "        indicators: list, List of all the indicators\n",
    "        \"\"\"\n",
    "        for indicator in indicators:\n",
    "            self.indicators.append(indicator)\n",
    "            print(f'{indicator.indicator_name} has been added to the data analysis pipeline')\n",
    "\n",
    "        self.tool = Data_analysis(self.name, self.indicators)   \n",
    "        self.tool.indicator_analysis()\n",
    "        return True\n",
    "\n",
    "    def indicator_analysis(self):\n",
    "        for indicator in self.indicators:\n",
    "            if indicator.condition is None:\n",
    "                df_copy = indicator.df\n",
    "            else:\n",
    "                df_copy = indicator.df\n",
    "                df_copy = df_copy[indicator.condition]\n",
    "            \n",
    "            indicator.df = df_copy\n",
    "            \n",
    "            self.tool.indicator_analysis()\n",
    "        \n",
    "        return print(\"All indicators have been calculated\")\n",
    " \n",
    "    def table_generation(self, file_path1, file_path2):\n",
    "        \"\"\"\n",
    "        - Generate tables from all the indicators\n",
    "        file_path1: str, a location where the tables will be saved\n",
    "        file_path2: str, a location where the chi2 test results will be saved\n",
    "        \"\"\"\n",
    "        empty_df1 = pd.DataFrame()\n",
    "        with pd.ExcelWriter(file_path1, engine='openpyxl') as writer:\n",
    "            empty_df1.to_excel(writer, sheet_name='Tables', index=False)\n",
    "            \n",
    "        empty_df2 = pd.DataFrame()\n",
    "        with pd.ExcelWriter(file_path2, engine='openpyxl') as writer:\n",
    "            empty_df2.to_excel(writer, sheet_name='Chi2 Tests', index=False)\n",
    "            \n",
    "        self.tool.tables(file_path1)\n",
    "        self.tool.chi2_test(file_path2)\n",
    "\n",
    "    def visual_generation(self, file_path):\n",
    "        \"\"\"\n",
    "        - Generate visuals from all the indicators\n",
    "        file_path: str, location where the visuals will be saved\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5577dbe9-42dc-4410-ad98-ded6d25a5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "azobe = Pipeline('Azobe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84c4a691-6a8e-430d-93dd-85e5cdc1f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAO111 has been added to the data analysis pipeline\n",
      "PROO141 has been added to the data analysis pipeline\n",
      "PROO311 has been added to the data analysis pipeline\n",
      "All indicators have been calculated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azobe.add_indicators([leao111,proo141,srhi311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d870596-5a6d-47eb-a98c-ce2b208c2d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square test statistic: 0.0\n",
      "P-value: 1.0\n",
      "Variable: 4 | There is not a significant association between variable and 4\n",
      "\n",
      "Chi-square test statistic: 7.078892035283014\n",
      "P-value: 0.21483882155498799\n",
      "Variable: s1 | There is not a significant association between variable and s1\n",
      "\n",
      "Chi-square test statistic: 0.1121213751521038\n",
      "P-value: 0.73774178635181\n",
      "Variable: 4 | There is not a significant association between variable and 4\n",
      "\n",
      "Chi-square test statistic: 95.38424252654193\n",
      "P-value: 4.956726752778344e-19\n",
      "Variable: s1 | There is a significant association between variable and s1\n",
      "\n",
      "Chi-square test statistic: 0.0\n",
      "P-value: 1.0\n",
      "Variable: 4 | There is not a significant association between variable and 4\n",
      "\n",
      "Chi-square test statistic: 13.812605042016807\n",
      "P-value: 0.08678246075001662\n",
      "Variable: s1 | There is not a significant association between variable and s1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path1 = 'data/table1.xlsx'\n",
    "file_path2 = 'data/table2.xlsx'\n",
    "azobe.table_generation(file_path1, file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3223a33-1697-4bae-b6ba-56c474c8eb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a001ac-e361-4bbf-92c5-b8fc85e9dae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a3943-583c-461d-93e6-13d3740191e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
